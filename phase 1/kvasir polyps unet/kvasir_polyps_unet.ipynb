{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pip install's for remote GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (1.12.1+cu116)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.13.1+cu116)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.12.1+cu116)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.28.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torchvision) (4.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.23.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchvision) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchvision) (2.8)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (1.23.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting torchmetrics\n",
      "  Downloading torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.5/841.5 kB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>17.1 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (23.0)\n",
      "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (1.23.4)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (1.12.1+cu116)\n",
      "Collecting lightning-utilities>=0.8.0\n",
      "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (66.1.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.4.0)\n",
      "Installing collected packages: lightning-utilities, torchmetrics\n",
      "Successfully installed lightning-utilities-0.11.2 torchmetrics-1.3.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting torchinfo\n",
      "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.8.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (3.6.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.23.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (1.1.2)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.9.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.23.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (3.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (1.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.9/dist-packages (from pandas) (1.23.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pytorch-toolbelt\n",
      "  Downloading pytorch_toolbelt-0.6.3-py3-none-any.whl (159 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.1/159.1 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: opencv-python>=4.1 in /usr/local/lib/python3.9/dist-packages (from pytorch-toolbelt) (4.6.0.66)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-toolbelt) (1.12.1+cu116)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from pytorch-toolbelt) (0.13.1+cu116)\n",
      "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-toolbelt) (1.9.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from opencv-python>=4.1->pytorch-toolbelt) (1.23.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->pytorch-toolbelt) (4.4.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision->pytorch-toolbelt) (2.28.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->pytorch-toolbelt) (9.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->pytorch-toolbelt) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchvision->pytorch-toolbelt) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchvision->pytorch-toolbelt) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->pytorch-toolbelt) (1.26.14)\n",
      "Installing collected packages: pytorch-toolbelt\n",
      "Successfully installed pytorch-toolbelt-0.6.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting segmentation-models-pytorch\n",
      "  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from segmentation-models-pytorch) (4.64.1)\n",
      "Collecting efficientnet-pytorch==0.7.1\n",
      "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pretrainedmodels==0.7.4\n",
      "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from segmentation-models-pytorch) (0.13.1+cu116)\n",
      "Collecting timm==0.9.2\n",
      "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from segmentation-models-pytorch) (9.2.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.12.1+cu116)\n",
      "Collecting munch\n",
      "  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
      "Collecting safetensors\n",
      "  Downloading safetensors-0.4.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.9/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (0.12.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (5.4.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.23.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (2.28.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (4.4.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (3.9.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2.8)\n",
      "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
      "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=35cb7f6face410eb6d46e4a3733faafc2079f639123a1259cb1a906db37d29c7\n",
      "  Stored in directory: /root/.cache/pip/wheels/22/16/f1/5369d23a06852d5f083d23a1addf0904575f1296f71b412ac8\n",
      "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60943 sha256=759588794b436921c6795aef5ec0f04f9f7466029bb687c3a2cafe6e8b10e591\n",
      "  Stored in directory: /root/.cache/pip/wheels/1f/9b/f5/9ccf39b50bc437986145107e2ced70a6fab622cf23e4795aa5\n",
      "Successfully built efficientnet-pytorch pretrainedmodels\n",
      "Installing collected packages: safetensors, munch, efficientnet-pytorch, timm, pretrainedmodels, segmentation-models-pytorch\n",
      "Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 pretrainedmodels-0.7.4 safetensors-0.4.3 segmentation-models-pytorch-0.3.3 timm-0.9.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install numpy\n",
    "!pip install torchmetrics\n",
    "!pip install torchinfo\n",
    "!pip install matplotlib\n",
    "!pip install scikit-learn\n",
    "!pip install pandas\n",
    "!pip install pytorch-toolbelt\n",
    "!pip install segmentation-models-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision import *\n",
    "from torchvision import datasets\n",
    "\n",
    "from torchmetrics import *\n",
    "from torchmetrics import JaccardIndex\n",
    "from torchmetrics import Dice\n",
    "\n",
    "from torch.utils.data import *\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import *\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import jaccard_score\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from skimage import io, color\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import compress\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataset import PolypsSegmentationDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 323061.23it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 325064.25it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 328090.11it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 306287.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# define path to images\n",
    "image_path = './Kvasir-SEG'\n",
    "size = 256\n",
    "# get dataset, need resize to be divisible by 16 for all 4 max pools, to keep \n",
    "# dim the same of up transpose\n",
    "# need tot check resize to see if random crop is correct\n",
    "# and check to normalize\n",
    "dataset = PolypsSegmentationDataset(image_path,size)\n",
    "augmented_dataset = PolypsSegmentationDataset(image_path,size,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "BATCH_SIZE = 16\n",
    "# converting dataset to dataloader, why does shuffle cause error?\n",
    "# dataloader = DataLoader(dataset = dataset, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torch/hub.py:266: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
      "  warnings.warn(\n",
      "Downloading: \"https://github.com/mateuszbuda/brain-segmentation-pytorch/zipball/master\" to /root/.cache/torch/hub/master.zip\n"
     ]
    }
   ],
   "source": [
    "# loading unet model from pytorch\n",
    "UNet = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
    "    in_channels=3, out_channels=1, init_features=64, pretrained=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training function\n",
    "def train(model, loss_fn, device, train_loader, optimizer, jaccard, dice):\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_iou = 0\n",
    "    total_dice = 0\n",
    "    \n",
    "    for batch_idx, (X, y) in enumerate(train_loader):\n",
    "        \n",
    "        # get x and y\n",
    "        X_train, y_train = X.to(device), y.to(device)\n",
    "        model.train()\n",
    "        # get output\n",
    "        output = model(X_train).to(device)\n",
    "        # compute loss\n",
    "        print(f\"Output: {output.shape} | Y: {y_train.shape}\")\n",
    "        loss = loss_fn(output, y_train)\n",
    "        total_loss += loss.item()\n",
    "        # compute IOU\n",
    "        iou = jaccard(torch.where(output > 0.5, 1, 0),torch.where(y_train > 0.50, 1, 0))\n",
    "        total_iou += iou\n",
    "        # compute dice score\n",
    "        dice_score = dice(torch.where(output > 0.5, 1, 0),torch.where(y_train > 0.50, 1, 0))\n",
    "        total_dice += dice_score\n",
    "        # optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f\"Train Loss: {total_loss / len(train_loader)} | Train IOU: {total_iou / len(train_loader)} | Train Dice: {total_dice / len(train_loader)}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of splits for data\n",
    "splits = 10\n",
    "# defining k-fold object\n",
    "kf = KFold(splits,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "lr = 0.001\n",
    "model = UNet.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "loss = torch.nn.BCELoss()\n",
    "jaccard = JaccardIndex(task= 'BINARY',num_classes = 1, threshold = 0.5).to(device)\n",
    "dice = Dice(average = 'micro', num_classes = 2, threshold = 0.5).to(device)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([4, 1, 256, 256]) | Y: torch.Size([4, 1, 256, 256])\n",
      "Train Loss: 0.42565210137450904 | Train IOU: 0.07838518917560577 | Train Dice: 0.8215853571891785\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n",
      "Output: torch.Size([16, 1, 256, 256]) | Y: torch.Size([16, 1, 256, 256])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#Train Model\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjaccard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#Decays learning rate after each kfold\u001b[39;00m\n\u001b[1;32m     22\u001b[0m lr_scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn [15], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, loss_fn, device, train_loader, optimizer, jaccard, dice)\u001b[0m\n\u001b[1;32m      5\u001b[0m total_iou \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      6\u001b[0m total_dice \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m      9\u001b[0m     \n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# get x and y\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     X_train, y_train \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/notebooks/dataset.py:53\u001b[0m, in \u001b[0;36mPolypsSegmentationDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m#scikit image rescaling\u001b[39;00m\n\u001b[1;32m     52\u001b[0m img_rescaled \u001b[38;5;241m=\u001b[39m resize(img, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_size))\n\u001b[0;32m---> 53\u001b[0m mask_rescaled \u001b[38;5;241m=\u001b[39m color\u001b[38;5;241m.\u001b[39mrgb2gray(\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     55\u001b[0m true_img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreshape(img_rescaled)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     56\u001b[0m true_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39munsqueeze(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(mask_rescaled),\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/skimage/transform/_warps.py:181\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(image, output_shape, order, mode, cval, clip, preserve_range, anti_aliasing, anti_aliasing_sigma)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many((anti_aliasing_sigma \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m&\u001b[39m (factors \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    179\u001b[0m             warn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnti-aliasing standard deviation greater than zero but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    180\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot down-sampling along all axes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 181\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mndi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgaussian_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manti_aliasing_sigma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mcval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndi_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m NumpyVersion(scipy\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1.6.0\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# The grid_mode kwarg was introduced in SciPy 1.6.0\u001b[39;00m\n\u001b[1;32m    186\u001b[0m     zoom_factors \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m factors]\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/scipy/ndimage/_filters.py:342\u001b[0m, in \u001b[0;36mgaussian_filter\u001b[0;34m(input, sigma, order, output, mode, cval, truncate)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(axes) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, sigma, order, mode \u001b[38;5;129;01min\u001b[39;00m axes:\n\u001b[0;32m--> 342\u001b[0m         \u001b[43mgaussian_filter1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m output\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/scipy/ndimage/_filters.py:261\u001b[0m, in \u001b[0;36mgaussian_filter1d\u001b[0;34m(input, sigma, axis, order, output, mode, cval, truncate)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# Since we are calling correlate, not convolve, revert the kernel\u001b[39;00m\n\u001b[1;32m    260\u001b[0m weights \u001b[38;5;241m=\u001b[39m _gaussian_kernel1d(sigma, order, lw)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 261\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcorrelate1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/scipy/ndimage/_filters.py:133\u001b[0m, in \u001b[0;36mcorrelate1d\u001b[0;34m(input, weights, axis, output, mode, cval, origin)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid origin; origin must satisfy \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    130\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-(len(weights) // 2) <= origin <= \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    131\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(len(weights)-1) // 2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    132\u001b[0m mode \u001b[38;5;241m=\u001b[39m _ni_support\u001b[38;5;241m.\u001b[39m_extend_mode_to_code(mode)\n\u001b[0;32m--> 133\u001b[0m \u001b[43m_nd_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrelate1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m                      \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(dataset)):\n",
    "    print(f\"Fold: {fold + 1}\")\n",
    "    # get test loader\n",
    "    train_loader = DataLoader(\n",
    "        dataset=augmented_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        sampler=torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "        )\n",
    "    # get train loader\n",
    "    test_loader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        sampler=torch.utils.data.SubsetRandomSampler(test_idx),\n",
    "    )\n",
    "    #Train Model\n",
    "    for i in range(5):\n",
    "        train(model, loss, device, train_loader, optimizer, jaccard, dice)\n",
    "    \n",
    "    #Decays learning rate after each kfold\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    #Evaluate model\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_IOU = 0\n",
    "    test_dice = 0\n",
    "    with torch.inference_mode():\n",
    "        for X, y in tqdm(test_loader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            output = model(X)\n",
    "            test_loss += loss(output, y).item()\n",
    "            test_IOU += jaccard(torch.where(output > 0.5, 1, 0),torch.where(y > 0.50, 1, 0)).item()\n",
    "            test_dice += dice(torch.where(output > 0.5, 1, 0),torch.where(y > 0.50, 1, 0)).item()\n",
    "\n",
    "    \n",
    "    test_loss /= len(test_loader)\n",
    "    test_IOU /= len(test_loader)\n",
    "    test_dice /= len(test_loader)\n",
    "    print(f\"Test set Average loss: {test_loss} | IOU: {test_IOU} | Dice: {test_dice}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jaccard Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = smp.losses.JaccardLoss('binary', log_loss = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "Train Loss: 1.8912871239478128 | Train IOU: 0.34438207745552063 | Train Dice: 0.875787079334259\n",
      "Train Loss: 1.8938223500000804 | Train IOU: 0.3476663827896118 | Train Dice: 0.8780691623687744\n",
      "Train Loss: 1.8956623537498607 | Train IOU: 0.3487612009048462 | Train Dice: 0.8775914311408997\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [78], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#Train Model\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjaccard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#Decays learning rate after each kfold\u001b[39;00m\n\u001b[1;32m     22\u001b[0m lr_scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn [66], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, loss_fn, device, train_loader, optimizer, jaccard, dice)\u001b[0m\n\u001b[1;32m      5\u001b[0m total_iou \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      6\u001b[0m total_dice \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m      9\u001b[0m     \n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# get x and y\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     X_train, y_train \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/notebooks/dataset.py:50\u001b[0m, in \u001b[0;36mPolypsSegmentationDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     47\u001b[0m mask \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasks[idx])\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m#scikit image rescaling\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m img_rescaled \u001b[38;5;241m=\u001b[39m \u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m mask_rescaled \u001b[38;5;241m=\u001b[39m color\u001b[38;5;241m.\u001b[39mrgb2gray(resize(mask, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_size)))\n\u001b[1;32m     53\u001b[0m true_img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreshape(img_rescaled)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/skimage/transform/_warps.py:181\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(image, output_shape, order, mode, cval, clip, preserve_range, anti_aliasing, anti_aliasing_sigma)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many((anti_aliasing_sigma \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m&\u001b[39m (factors \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    179\u001b[0m             warn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnti-aliasing standard deviation greater than zero but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    180\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot down-sampling along all axes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 181\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mndi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgaussian_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manti_aliasing_sigma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mcval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndi_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m NumpyVersion(scipy\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1.6.0\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# The grid_mode kwarg was introduced in SciPy 1.6.0\u001b[39;00m\n\u001b[1;32m    186\u001b[0m     zoom_factors \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m factors]\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/scipy/ndimage/_filters.py:342\u001b[0m, in \u001b[0;36mgaussian_filter\u001b[0;34m(input, sigma, order, output, mode, cval, truncate)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(axes) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, sigma, order, mode \u001b[38;5;129;01min\u001b[39;00m axes:\n\u001b[0;32m--> 342\u001b[0m         \u001b[43mgaussian_filter1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m output\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/scipy/ndimage/_filters.py:261\u001b[0m, in \u001b[0;36mgaussian_filter1d\u001b[0;34m(input, sigma, axis, order, output, mode, cval, truncate)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# Since we are calling correlate, not convolve, revert the kernel\u001b[39;00m\n\u001b[1;32m    260\u001b[0m weights \u001b[38;5;241m=\u001b[39m _gaussian_kernel1d(sigma, order, lw)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 261\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcorrelate1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/scipy/ndimage/_filters.py:133\u001b[0m, in \u001b[0;36mcorrelate1d\u001b[0;34m(input, weights, axis, output, mode, cval, origin)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid origin; origin must satisfy \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    130\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-(len(weights) // 2) <= origin <= \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    131\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(len(weights)-1) // 2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    132\u001b[0m mode \u001b[38;5;241m=\u001b[39m _ni_support\u001b[38;5;241m.\u001b[39m_extend_mode_to_code(mode)\n\u001b[0;32m--> 133\u001b[0m \u001b[43m_nd_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrelate1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m                      \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(dataset)):\n",
    "    print(f\"Fold: {fold + 1}\")\n",
    "    # get test loader\n",
    "    train_loader = DataLoader(\n",
    "        dataset= transformation(dataset),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        sampler=torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "        )\n",
    "    # get train loader\n",
    "    test_loader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        sampler=torch.utils.data.SubsetRandomSampler(test_idx),\n",
    "    )\n",
    "    #Train Model\n",
    "    for i in range(5):\n",
    "        train(model, loss, device, train_loader, optimizer, jaccard, dice)\n",
    "    \n",
    "    #Decays learning rate after each kfold\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    #Evaluate model\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_IOU = 0\n",
    "    test_dice = 0\n",
    "    with torch.inference_mode():\n",
    "        for X, y in tqdm(test_loader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            output = model(X)\n",
    "            test_loss += loss(output, y).item()\n",
    "            test_IOU += jaccard(torch.where(output > 0.5, 1, 0),torch.where(y > 0.50, 1, 0)).item()\n",
    "            test_dice += dice(torch.where(output > 0.5, 1, 0),torch.where(y > 0.50, 1, 0)).item()\n",
    "\n",
    "    \n",
    "    test_loss /= len(test_loader)\n",
    "    test_IOU /= len(test_loader)\n",
    "    test_dice /= len(test_loader)\n",
    "    print(f\"Test set Average loss: {test_loss} | IOU: {test_IOU} | Dice: {test_dice}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8a80e02760>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(y[3].cpu().permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8a80ce63d0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.where(output > 0.5, 1, 0)\n",
    "plt.imshow(x[3].cpu().permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2342, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(jaccard(torch.where(output > 0.35, 1, 0),torch.where(y > 0.40, 1, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "update() got an unexpected keyword argument 'num_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [38], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#print(loss(output,y))\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m dice \u001b[38;5;241m=\u001b[39m \u001b[43mjaccard\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmicro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(dice(torch\u001b[38;5;241m.\u001b[39mwhere(output \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.50\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m),torch\u001b[38;5;241m.\u001b[39mwhere(y \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.40\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)))\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchmetrics/metric.py:304\u001b[0m, in \u001b[0;36mMetric.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_full_state_update(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_reduce_state_update\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchmetrics/metric.py:373\u001b[0m, in \u001b[0;36mMetric._forward_reduce_state_update\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# allow grads for batch computation\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# calculate batch state and compute batch value\u001b[39;00m\n\u001b[0;32m--> 373\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m batch_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# reduce batch and global state\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchmetrics/metric.py:466\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad):\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m         \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    468\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected all tensors to be on\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "\u001b[0;31mTypeError\u001b[0m: update() got an unexpected keyword argument 'num_classes'"
     ]
    }
   ],
   "source": [
    "#print(loss(output,y))\n",
    "\n",
    "print(dice(torch.where(output > 0.50, 1, 0),torch.where(y > 0.40, 1, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/13 [00:00<00:07,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3947315812110901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 2/13 [00:01<00:08,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7293487787246704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 3/13 [00:02<00:08,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0140481293201447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 4/13 [00:02<00:05,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.4639271199703217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 5/13 [00:03<00:04,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.7604164779186249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 6/13 [00:03<00:03,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.129318207502365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 7/13 [00:03<00:02,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.4442706406116486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 8/13 [00:04<00:02,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.740805983543396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 9/13 [00:04<00:01,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.0997469425201416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 10/13 [00:04<00:01,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.425353080034256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 11/13 [00:05<00:00,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.699008136987686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:05<00:00,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.033684074878693\n",
      "Loss: 4.262686043977737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "with torch.inference_mode():\n",
    "    for X, y in tqdm(test_loader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        output = model(X)\n",
    "        test_loss += loss(output, y).item()\n",
    "        print(f\"Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32789892645982593"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss / len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:05<00:00,  2.57it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "test_accuracy = 0\n",
    "with torch.inference_mode():\n",
    "    for X, y in tqdm(test_loader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        output = model(X)\n",
    "        test_loss += loss(output, y).item()\n",
    "        test_accuracy += jaccard(torch.where(output > 0.40, 1, 0),torch.where(y > 0.40, 1, 0)).item()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33271955297543454"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss / len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
