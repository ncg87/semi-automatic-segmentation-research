{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# for images\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "#everything else\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision import *\n",
    "from torchvision import datasets\n",
    "\n",
    "from torchmetrics import *\n",
    "\n",
    "from torch.utils.data import *\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import *\n",
    "from sklearn import svm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import compress\n",
    "\n",
    "from dataset import PolypsSegmentationDataset\n",
    "from UNet import Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_path = Path(f'{image_path}/images/')\n",
    "y_path = Path(f'{image_path}/masks/')\n",
    "\n",
    "# get path to all images and put in list\n",
    "x_filenames = list(x_path.glob(r'**/*.jpg'))\n",
    "y_filenames = list(y_path.glob(r'**/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Reading {image_path}...')\n",
    "images = sorted([image_path + \"/images\" + i for i in tqdm(os.listdir(image_path + \"/images/\"))])\n",
    "masks = sorted([image_path + \"/images\" + i for i in tqdm(os.listdir(image_path + \"/masks/\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_images = []\n",
    "y_images = []\n",
    "\n",
    "print(f'Reading {x_path} to list...')\n",
    "\n",
    "for filename in tqdm(x_filenames):\n",
    "    # load the image (filename) in color (1)\n",
    "    img = cv2.imread(str(filename), 1)\n",
    "    # resizing to u-net specifications of 256 x 256\n",
    "    img = cv2.resize(img, (256,256))\n",
    "    # normalizing image\n",
    "    img = img / 255\n",
    "    #resizing to one vector\n",
    "    img = img.reshape(-1,3).shape\n",
    "    x_images.append(img)\n",
    "\n",
    "print(f'Reading {y_path} to list...')\n",
    "for filename in tqdm(x_filenames):\n",
    "    # load the image (filename) in color (1)\n",
    "    img = cv2.imread(str(filename), 1)\n",
    "    # resizing to u-net specifications of 256 x 256\n",
    "    img = cv2.resize(img, (256,256))\n",
    "    # normalizing image\n",
    "    img = img / 255\n",
    "    #resizing to one vector\n",
    "    img = img.reshape(-1,3).shape\n",
    "    x_images.append(img)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHOWING IMAGE FROM A DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#plot image in color if image is in color or black and white\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m random \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mrandom((\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m100\u001b[39m))\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(random\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "#plot image in color if image is in color or black and white if dim\n",
    "#are (colors,height,width)\n",
    "random = torch.random((3,100,100))\n",
    "plt.imshow(random.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get and show an image from a dataset\n",
    "image = dataset.__getitem__(100)[1]\n",
    "plt.imshow(image.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x = torch.where(output > 0.40, 1, 0)\n",
    "plt.imshow(x[0].cpu().permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = dataset.masks[1]\n",
    "ski_image = io.imread(img)\n",
    "new = color.rgb2gray(resize(ski_image, (256,256)))\n",
    "plt.imshow(new_img.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = dataset.images[1]\n",
    "ski_image = io.imread(img)\n",
    "new = resize(ski_image, (256,256))\n",
    "reshaping_list = []\n",
    "for i in range(new.shape[2]):\n",
    "    reshaping_list.append(torch.unsqueeze(torch.from_numpy(new[:,:,i]),0))\n",
    "new_img = torch.concat(reshaping_list, 0)\n",
    "plt.imshow(new_img.permute(1,2,0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
