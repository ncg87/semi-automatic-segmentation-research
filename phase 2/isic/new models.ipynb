{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T04:18:05.100477Z",
     "iopub.status.busy": "2024-09-14T04:18:05.099874Z",
     "iopub.status.idle": "2024-09-14T04:18:10.052600Z",
     "shell.execute_reply": "2024-09-14T04:18:10.052058Z",
     "shell.execute_reply.started": "2024-09-14T04:18:05.100455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.1.1+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torchmetrics in /usr/local/lib/python3.11/dist-packages (1.4.1)\n",
      "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (1.26.3)\n",
      "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (23.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.1.1+cu121)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (0.11.7)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (69.0.3)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.9.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "Packages required for experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T04:18:10.053696Z",
     "iopub.status.busy": "2024-09-14T04:18:10.053527Z",
     "iopub.status.idle": "2024-09-14T04:18:12.641126Z",
     "shell.execute_reply": "2024-09-14T04:18:12.640455Z",
     "shell.execute_reply.started": "2024-09-14T04:18:10.053677Z"
    }
   },
   "outputs": [],
   "source": [
    "# General use for DL\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# To loader dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Data Measurements\n",
    "from torchmetrics import JaccardIndex\n",
    "from torchmetrics import Dice\n",
    "\n",
    "# Dataset import\n",
    "from dataset import ISICSegmentationDataset\n",
    "from base_dataset import BaseDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopping Rule\n",
    "When this function returns a value less than 0.1 % = 0.001 then we know to stop training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T04:18:12.642114Z",
     "iopub.status.busy": "2024-09-14T04:18:12.641810Z",
     "iopub.status.idle": "2024-09-14T04:18:12.644967Z",
     "shell.execute_reply": "2024-09-14T04:18:12.644452Z",
     "shell.execute_reply.started": "2024-09-14T04:18:12.642092Z"
    }
   },
   "outputs": [],
   "source": [
    "# Finds percent change between previous and current loss\n",
    "# and if it is less than threshold return false\n",
    "def stopping_rule(L_k, L_k1, threshold):\n",
    "    return abs(L_k - L_k1) / L_k > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the moving average\n",
    "def moving_avg(alpha, L_MA, L_k):\n",
    "    return alpha * L_MA + (1-alpha) * L_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T04:18:12.646227Z",
     "iopub.status.busy": "2024-09-14T04:18:12.646067Z",
     "iopub.status.idle": "2024-09-14T04:18:12.650019Z",
     "shell.execute_reply": "2024-09-14T04:18:12.649531Z",
     "shell.execute_reply.started": "2024-09-14T04:18:12.646218Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, loss_fn, device, train_loader, optimizer):\n",
    "    # Initalize loss\n",
    "    average_loss = 0\n",
    "    # Train on dataset\n",
    "    model.train()\n",
    "    for batch_idx, (X,y) in enumerate(train_loader):\n",
    "        # Get batch\n",
    "        image, mask = X.to(device), y.to(device)\n",
    "        # Get results\n",
    "        output = model(image)\n",
    "        # Compute loss\n",
    "        loss = loss_fn(output, mask)\n",
    "        average_loss += loss.item()\n",
    "        # Optimize model\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # Return average loss\n",
    "    return average_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T04:18:12.650746Z",
     "iopub.status.busy": "2024-09-14T04:18:12.650623Z",
     "iopub.status.idle": "2024-09-14T04:18:15.259391Z",
     "shell.execute_reply": "2024-09-14T04:18:15.258884Z",
     "shell.execute_reply.started": "2024-09-14T04:18:12.650746Z"
    }
   },
   "outputs": [],
   "source": [
    "## Preliminary variables ##\n",
    "\n",
    "# Specifies whether to train on GPU or CPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Loss for training\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "# Measurements\n",
    "jaccard = JaccardIndex(task='multiclass', num_classes = 2, average = 'micro').to(device)\n",
    "dice = Dice(num_classes = 2, average = 'micro').to(device)\n",
    "\n",
    "# Batch Size\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Stopping threshold\n",
    "threshold = 0.001\n",
    "\n",
    "# Speeds up training\n",
    "num_workers = 8\n",
    "\n",
    "# Alpha for EMA\n",
    "alpha = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Masks\n",
    "Function to extracts iamges and masks of given indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T04:18:15.260279Z",
     "iopub.status.busy": "2024-09-14T04:18:15.260091Z",
     "iopub.status.idle": "2024-09-14T04:18:15.263097Z",
     "shell.execute_reply": "2024-09-14T04:18:15.262700Z",
     "shell.execute_reply.started": "2024-09-14T04:18:15.260261Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_masks(indices, dataset):\n",
    "    masks = []\n",
    "    images = []\n",
    "    for i in indices:\n",
    "        image, mask = dataset.__getitem__(i)\n",
    "        images.append(image)\n",
    "        masks.append(mask)\n",
    "    return images, masks\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Masks\n",
    "Function to create masks of given images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T04:18:15.263986Z",
     "iopub.status.busy": "2024-09-14T04:18:15.263798Z",
     "iopub.status.idle": "2024-09-14T04:18:15.268175Z",
     "shell.execute_reply": "2024-09-14T04:18:15.267555Z",
     "shell.execute_reply.started": "2024-09-14T04:18:15.263968Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_masks(model, device, loader):\n",
    "    # Initialize \n",
    "    masks = []\n",
    "    images = []\n",
    "    # Create masks\n",
    "    model.eval()\n",
    "    for batch_idx, (X,y) in enumerate(loader):\n",
    "        # Get batch\n",
    "        image, mask = X.to(device), y.to(device)\n",
    "        # Get results\n",
    "        output = model(image)\n",
    "        # Detach from CPU and squeeze batch(1) dimension\n",
    "        masks.append(output.detach().cpu().squeeze(0))\n",
    "        images.append(image.detach().cpu().squeeze(0))\n",
    "    # Segmented masks\n",
    "    return images, masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T04:18:15.269178Z",
     "iopub.status.busy": "2024-09-14T04:18:15.269029Z",
     "iopub.status.idle": "2024-09-14T04:18:15.273081Z",
     "shell.execute_reply": "2024-09-14T04:18:15.272604Z",
     "shell.execute_reply.started": "2024-09-14T04:18:15.269163Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_model(model, device, test_loader, jaccard, dice):\n",
    "    # Initalize average jaccard and dice\n",
    "    average_jaccard = 0\n",
    "    average_dice = 0\n",
    "    # Test the model\n",
    "    model.eval()\n",
    "    for batch_idx, (X,y) in enumerate(test_loader):\n",
    "        # Get batch\n",
    "        image, mask = X.to(device), y.to(device)\n",
    "        # Get results\n",
    "        output = model(image)\n",
    "        average_jaccard += jaccard(torch.where(output > 0.5, 1, 0),torch.where(mask > 0.50, 1, 0)).item()\n",
    "        average_dice += dice(torch.where(output > 0.5, 1, 0),torch.where(mask > 0.50, 1, 0)).item()\n",
    "    # Get average of dice and jaccard scores\n",
    "    average_jaccard /= len(test_loader)\n",
    "    average_dice /= len(test_loader)\n",
    "\n",
    "    # Return values\n",
    "    return average_jaccard, average_dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "Importing the dataset into the Juypter Notebook enviroment for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T04:18:15.273726Z",
     "iopub.status.busy": "2024-09-14T04:18:15.273593Z",
     "iopub.status.idle": "2024-09-14T04:18:15.390519Z",
     "shell.execute_reply": "2024-09-14T04:18:15.389966Z",
     "shell.execute_reply.started": "2024-09-14T04:18:15.273713Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2594/2594 [00:00<00:00, 3712052.06it/s]\n",
      "100%|██████████| 2594/2594 [00:00<00:00, 3631516.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# Paths to masks and images\n",
    "image_path = \"./ISIC/images/ISIC2018_Task1-2_Training_Input/\"\n",
    "masks_path = \"./ISIC/masks/ISIC2018_Task1_Training_GroundTruth/\"\n",
    "# Size of image\n",
    "size = 256\n",
    "# Define dataset\n",
    "dataset = ISICSegmentationDataset(image_path, masks_path, size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "Load the baseline data and indices splits from previous stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T04:18:15.391981Z",
     "iopub.status.busy": "2024-09-14T04:18:15.391820Z",
     "iopub.status.idle": "2024-09-14T04:18:15.399555Z",
     "shell.execute_reply": "2024-09-14T04:18:15.398905Z",
     "shell.execute_reply.started": "2024-09-14T04:18:15.391966Z"
    }
   },
   "outputs": [],
   "source": [
    "# File name\n",
    "name = 'baseline.pt'\n",
    "baseline = torch.load(f=name)\n",
    "# Extract indices and baseline jaccard and dice scores\n",
    "all_indices = baseline['fold_dict']\n",
    "baseline_jaccard = baseline['baseline_jaccard']\n",
    "baseline_dice = baseline['baseline_dice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new dataset\n",
    "Using the model trained on a partition we will create masks the remaining data from the train partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T04:18:15.400401Z",
     "iopub.status.busy": "2024-09-14T04:18:15.400250Z",
     "iopub.status.idle": "2024-09-14T17:28:41.911373Z",
     "shell.execute_reply": "2024-09-14T17:28:41.910712Z",
     "shell.execute_reply.started": "2024-09-14T04:18:15.400387Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "Split:A|Partition:0.1|NewJaccard:0.8328580458958944|OGJaccard:0.8005861387108312|NewDice:0.9082560232191375|OGDice:0.8886485153978522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "Split:A|Partition:0.2|NewJaccard:0.823756481661941|OGJaccard:0.8260780067154856|NewDice:0.902275769999533|OGDice:0.9038065671920776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "Split:A|Partition:0.3|NewJaccard:0.834005305261323|OGJaccard:0.8396076957384745|NewDice:0.9088735995870648|OGDice:0.9117339741099965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Split:A|Partition:0.4|NewJaccard:0.8102510047681404|OGJaccard:0.8023915778506886|NewDice:0.8945544849742543|OGDice:0.8897204055930629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "Split:A|Partition:0.5|NewJaccard:0.9001473784446716|OGJaccard:0.8930019971096155|NewDice:0.947074476516608|OGDice:0.9432177724260272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "Split:A|Partition:0.6|NewJaccard:0.8947329792109403|OGJaccard:0.8860039169138129|NewDice:0.944011056061947|OGDice:0.9390563513293411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "Split:A|Partition:0.7|NewJaccard:0.8962158217574611|OGJaccard:0.9002582141847322|NewDice:0.9446930487950643|OGDice:0.9471398230754968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "Split:B|Partition:0.1|NewJaccard:0.7772222865711559|OGJaccard:0.7807320591175195|NewDice:0.8726213303479281|OGDice:0.8752328861843456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "Split:B|Partition:0.2|NewJaccard:0.8658977891459609|OGJaccard:0.8660176775672219|NewDice:0.927350969025583|OGDice:0.9273869937116449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n",
      "Split:B|Partition:0.3|NewJaccard:0.8906751275062561|OGJaccard:0.8739764383344939|NewDice:0.9417863036646987|OGDice:0.9322500427563986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "Split:B|Partition:0.4|NewJaccard:0.895634544618202|OGJaccard:0.8926929072900252|NewDice:0.9446266636703954|OGDice:0.9429937745585586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Split:B|Partition:0.5|NewJaccard:0.8729685274037448|OGJaccard:0.8398388136516918|NewDice:0.9317316828352032|OGDice:0.9125800186937506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "Split:B|Partition:0.6|NewJaccard:0.8918473756674564|OGJaccard:0.8900907744060863|NewDice:0.9425324364141985|OGDice:0.9414529962973162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "Split:B|Partition:0.7|NewJaccard:0.8891258113311998|OGJaccard:0.883630431059635|NewDice:0.940983280991063|OGDice:0.9378901647798943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n",
      "Split:C|Partition:0.1|NewJaccard:0.8577379999738751|OGJaccard:0.8450681747812213|NewDice:0.9230032834139738|OGDice:0.9156237930962534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Split:C|Partition:0.2|NewJaccard:0.8757391102386244|OGJaccard:0.8666279045018283|NewDice:0.933282303087639|OGDice:0.928167310628024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "Split:C|Partition:0.3|NewJaccard:0.8439733097047517|OGJaccard:0.8483899253787417|NewDice:0.9146057096394625|OGDice:0.9174740206111561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Split:C|Partition:0.4|NewJaccard:0.8823944655331698|OGJaccard:0.8869172443043102|NewDice:0.9371631958267905|OGDice:0.9397015138105913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "Split:C|Partition:0.5|NewJaccard:0.8887879505301967|OGJaccard:0.8901004917693861|NewDice:0.940779239842386|OGDice:0.9413657585779825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "Split:C|Partition:0.6|NewJaccard:0.8910806757031065|OGJaccard:0.8919210614580096|NewDice:0.9420594428524827|OGDice:0.942535111398408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "Split:C|Partition:0.7|NewJaccard:0.8974887439698884|OGJaccard:0.8819074450117169|NewDice:0.9455887187610973|OGDice:0.9368810364694307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "Split:D|Partition:0.1|NewJaccard:0.792255851355466|OGJaccard:0.7772848804791769|NewDice:0.8833158828995444|OGDice:0.8730095209497394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "Split:D|Partition:0.2|NewJaccard:0.8768581206148321|OGJaccard:0.8722107916167288|NewDice:0.9339657696810636|OGDice:0.9309458588108872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "Split:D|Partition:0.3|NewJaccard:0.8875501264225353|OGJaccard:0.8847688273950056|NewDice:0.9398159511161573|OGDice:0.9382852370088751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "Split:D|Partition:0.4|NewJaccard:0.8720780195611896|OGJaccard:0.8799027150327509|NewDice:0.9309219392863187|OGDice:0.9354553186532223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Split:D|Partition:0.5|NewJaccard:0.8104832660068165|OGJaccard:0.8305145736896631|NewDice:0.8944107601136873|OGDice:0.9064425970568801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Split:D|Partition:0.6|NewJaccard:0.8649323293657014|OGJaccard:0.8316080479910879|NewDice:0.9270441297328833|OGDice:0.9074085499301101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "Split:D|Partition:0.7|NewJaccard:0.893074833985531|OGJaccard:0.8313601269866481|NewDice:0.9431628801605918|OGDice:0.9072384111809008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161\n",
      "Split:E|Partition:0.1|NewJaccard:0.8220972057544824|OGJaccard:0.7971197926636898|NewDice:0.9015412095821265|OGDice:0.8853532328750148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Split:E|Partition:0.2|NewJaccard:0.774028870192441|OGJaccard:0.7271572893316095|NewDice:0.870843069119887|OGDice:0.8401159517692797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "Split:E|Partition:0.3|NewJaccard:0.7658198457775693|OGJaccard:0.8201130592461788|NewDice:0.8660906101718093|OGDice:0.8999443252881368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "Split:E|Partition:0.4|NewJaccard:0.8022179585514646|OGJaccard:0.7868092385205355|NewDice:0.8882634332685759|OGDice:0.8782555460929871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "Split:E|Partition:0.5|NewJaccard:0.8852056535807523|OGJaccard:0.8829007509982947|NewDice:0.9386203451590105|OGDice:0.9371938506762186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "Split:E|Partition:0.6|NewJaccard:0.8837962746620178|OGJaccard:0.8637632167700565|NewDice:0.9380025086980878|OGDice:0.9265058889533534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "Split:E|Partition:0.7|NewJaccard:0.8741676446163293|OGJaccard:0.8878839413324991|NewDice:0.932399798523296|OGDice:0.940051636912606\n"
     ]
    }
   ],
   "source": [
    "splits = ['A', 'B', 'C', 'D', 'E']\n",
    "partitions = [0.1,0.2,0.3,0.4,0.5,0.6,0.7]\n",
    "\n",
    "# Cycle through all models\n",
    "for split in splits:\n",
    "    for partition in partitions:\n",
    "        # Load the stored data\n",
    "        name = f'./model/Split:{split}|Partition:{partition}|New'\n",
    "        data = torch.load(name)\n",
    "        # Extract data\n",
    "        train_indices = data['train_indices']\n",
    "        remaining_indices = data['remaining_indices']\n",
    "        test_indices = data['test_indices']\n",
    "        orig_jaccard_score = data['jaccard_score']\n",
    "        orig_dice_score = data['dice_score']\n",
    "        orig_iterations = data['num_iterations']\n",
    "        state_dict = data['state_dict']\n",
    "        # Load base model\n",
    "        trained_model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
    "            in_channels=3, out_channels=1, init_features=64, pretrained=False, trust_repo=True).to(device)\n",
    "        # Load saved model\n",
    "        trained_model.load_state_dict(state_dict)\n",
    "        \n",
    "        # Create new dataset\n",
    "        new_dataset = []\n",
    "        # Get train loader for fold\n",
    "        remaining_loader = DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=1,\n",
    "            sampler=torch.utils.data.SubsetRandomSampler(remaining_indices),\n",
    "            num_workers = num_workers\n",
    "        )\n",
    "        # Create masks of remaining data\n",
    "        images, new_masks = create_masks(trained_model, device, remaining_loader)\n",
    "        # Create dataset with new masks\n",
    "        new_dataset.append(BaseDataset(images, new_masks))\n",
    "        # Get images and masks used to train saved model\n",
    "        base_images, base_masks = get_masks(train_indices,dataset)\n",
    "        # Create dataset with ground truth masks and images\n",
    "        new_dataset.append(BaseDataset(base_images, base_masks))\n",
    "        # Concatenate the two so we have a dataset with generated masks and truth maks\n",
    "        # this will be our train dataset\n",
    "        train_dataset = torch.utils.data.ConcatDataset(new_dataset)\n",
    "        \n",
    "        # Create train loader for new dataset\n",
    "        train_loader = DataLoader(\n",
    "            dataset=train_dataset,\n",
    "            batch_size = BATCH_SIZE,\n",
    "            shuffle = True,\n",
    "            num_workers = num_workers,\n",
    "        )    \n",
    "        \n",
    "        ## Initialize the model ##\n",
    "        \n",
    "        # We will begin our learning rate at 0.01 \n",
    "        lr = 0.01\n",
    "        # Optimizer for model\n",
    "        optimizer = torch.optim.Adam(trained_model.parameters(), lr)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,100)\n",
    "        \n",
    "        ## Initialize the training ##\n",
    "    \n",
    "        # Initialize previous and current loss for stopping rule\n",
    "        \n",
    "        L_MA = 1 # Moving average of loss\n",
    "        L_k = 0 # Current loss\n",
    "        \n",
    "        # To determine in threshold is too low\n",
    "        counter = 0\n",
    "        # Train model until stopping rule is reached\n",
    "        while(stopping_rule(L_MA, L_k, threshold) or counter < 10):\n",
    "            # Train model and compute loss\n",
    "            L_k = train_model(trained_model, loss_fn, device, train_loader, optimizer)\n",
    "            \n",
    "            # Initialization\n",
    "            if(L_MA == 0):\n",
    "                L_MA = L_k\n",
    "            \n",
    "            # Find EMA of losses\n",
    "            L_MA = moving_avg(alpha, L_MA, L_k)\n",
    "            counter += 1\n",
    "            \n",
    "        # To determine in threshold is too low\n",
    "        print(counter) \n",
    "        \n",
    "        # Get test dataset\n",
    "        test_loader = DataLoader(\n",
    "                dataset=dataset,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                sampler=torch.utils.data.SubsetRandomSampler(test_indices),\n",
    "                num_workers = num_workers,\n",
    "        )\n",
    "        \n",
    "        # Test model on test split\n",
    "        jaccard_score, dice_score = test_model(model, device, test_loader, jaccard, dice)\n",
    "        print(f'Split:{split}|Partition:{partition}|NewJaccard:{jaccard_score}|OGJaccard:{orig_jaccard_score}|NewDice:{dice_score}|OGDice:{orig_dice_score}')\n",
    "        name = f'./new_models/Split:{split}|Partition:{partition}|New'\n",
    "        # Save model and results\n",
    "        state = {\n",
    "            'state_dict' : model.state_dict(),\n",
    "            'jaccard_score' : jaccard_score,\n",
    "            'dice_score' : dice_score,\n",
    "            'num_iterations' : counter,\n",
    "            'orig_jaccard_score' : orig_jaccard_score,\n",
    "            'orig_dice_score' : orig_dice_score,\n",
    "            'orig_iterations' : orig_iterations,\n",
    "        }\n",
    "        torch.save(state,f=name)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
