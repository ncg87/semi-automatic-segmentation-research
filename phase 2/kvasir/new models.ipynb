{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T01:11:25.149120Z",
     "iopub.status.busy": "2024-08-25T01:11:25.148471Z",
     "iopub.status.idle": "2024-08-25T01:11:32.265454Z",
     "shell.execute_reply": "2024-08-25T01:11:32.264539Z",
     "shell.execute_reply.started": "2024-08-25T01:11:25.149090Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (1.12.1+cu116)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting torchmetrics\n",
      "  Downloading torchmetrics-1.4.1-py3-none-any.whl (866 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m866.2/866.2 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (1.12.1+cu116)\n",
      "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (1.23.4)\n",
      "Collecting lightning-utilities>=0.8.0\n",
      "  Downloading lightning_utilities-0.11.6-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (23.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.4.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (66.1.1)\n",
      "Installing collected packages: lightning-utilities, torchmetrics\n",
      "Successfully installed lightning-utilities-0.11.6 torchmetrics-1.4.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "Packages required for experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T01:11:32.268020Z",
     "iopub.status.busy": "2024-08-25T01:11:32.267365Z",
     "iopub.status.idle": "2024-08-25T01:11:35.671153Z",
     "shell.execute_reply": "2024-08-25T01:11:35.670248Z",
     "shell.execute_reply.started": "2024-08-25T01:11:32.267985Z"
    }
   },
   "outputs": [],
   "source": [
    "# General use for DL\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# To loader dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Data Measurements\n",
    "from torchmetrics import JaccardIndex\n",
    "from torchmetrics import Dice\n",
    "\n",
    "# Dataset import\n",
    "from dataset import PolypsSegmentationDataset\n",
    "from base_dataset import BaseDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopping Rule\n",
    "When this function returns a value less than 0.1 % = 0.001 then we know to stop training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T01:11:35.673782Z",
     "iopub.status.busy": "2024-08-25T01:11:35.672660Z",
     "iopub.status.idle": "2024-08-25T01:11:35.677420Z",
     "shell.execute_reply": "2024-08-25T01:11:35.676875Z",
     "shell.execute_reply.started": "2024-08-25T01:11:35.673716Z"
    }
   },
   "outputs": [],
   "source": [
    "# Finds percent change between previous and current loss\n",
    "# and if it is less than threshold return false\n",
    "def stopping_rule(L_k, L_k1, threshold):\n",
    "    return abs(L_k - L_k1) / L_k > threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T01:11:35.679683Z",
     "iopub.status.busy": "2024-08-25T01:11:35.679021Z",
     "iopub.status.idle": "2024-08-25T01:11:35.684551Z",
     "shell.execute_reply": "2024-08-25T01:11:35.684036Z",
     "shell.execute_reply.started": "2024-08-25T01:11:35.679658Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, loss_fn, device, train_loader, optimizer):\n",
    "    # Initalize loss\n",
    "    average_loss = 0\n",
    "    # Train on dataset\n",
    "    model.train()\n",
    "    for batch_idx, (X,y) in enumerate(train_loader):\n",
    "        # Get batch\n",
    "        image, mask = X.to(device), y.to(device)\n",
    "        # Get results\n",
    "        output = model(image)\n",
    "        # Compute loss\n",
    "        loss = loss_fn(output, mask)\n",
    "        average_loss += loss.item()\n",
    "        # Optimize model\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # Return average loss\n",
    "    return average_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T01:11:35.685993Z",
     "iopub.status.busy": "2024-08-25T01:11:35.685296Z",
     "iopub.status.idle": "2024-08-25T01:11:38.359168Z",
     "shell.execute_reply": "2024-08-25T01:11:38.358563Z",
     "shell.execute_reply.started": "2024-08-25T01:11:35.685968Z"
    }
   },
   "outputs": [],
   "source": [
    "## Preliminary variables ##\n",
    "\n",
    "# Specifies whether to train on GPU or CPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Loss for training\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "# Measurements\n",
    "jaccard = JaccardIndex(task='multiclass', num_classes = 2, average = 'micro').to(device)\n",
    "dice = Dice(num_classes = 2, average = 'micro').to(device)\n",
    "\n",
    "# Batch Size\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Stopping threshold\n",
    "threshold = 0.001\n",
    "\n",
    "# Speeds up training\n",
    "num_workers = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Masks\n",
    "Function to extracts iamges and masks of given indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T01:11:38.360783Z",
     "iopub.status.busy": "2024-08-25T01:11:38.360533Z",
     "iopub.status.idle": "2024-08-25T01:11:38.364546Z",
     "shell.execute_reply": "2024-08-25T01:11:38.363921Z",
     "shell.execute_reply.started": "2024-08-25T01:11:38.360760Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_masks(indices, dataset):\n",
    "    masks = []\n",
    "    images = []\n",
    "    for i in indices:\n",
    "        image, mask = dataset.__getitem__(i)\n",
    "        images.append(image)\n",
    "        masks.append(mask)\n",
    "    return images, masks\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Masks\n",
    "Function to create masks of given images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T01:11:38.365643Z",
     "iopub.status.busy": "2024-08-25T01:11:38.365380Z",
     "iopub.status.idle": "2024-08-25T01:11:38.370610Z",
     "shell.execute_reply": "2024-08-25T01:11:38.370051Z",
     "shell.execute_reply.started": "2024-08-25T01:11:38.365622Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_masks(model, device, loader):\n",
    "    # Initialize \n",
    "    masks = []\n",
    "    images = []\n",
    "    # Create masks\n",
    "    model.eval()\n",
    "    for batch_idx, (X,y) in enumerate(loader):\n",
    "        # Get batch\n",
    "        image, mask = X.to(device), y.to(device)\n",
    "        # Get results\n",
    "        output = model(image)\n",
    "        # Detach from CPU and squeeze batch(1) dimension\n",
    "        masks.append(output.detach().cpu().squeeze(0))\n",
    "        images.append(image.detach().cpu().squeeze(0))\n",
    "    # Segmented masks\n",
    "    return images, masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T01:11:38.371704Z",
     "iopub.status.busy": "2024-08-25T01:11:38.371487Z",
     "iopub.status.idle": "2024-08-25T01:11:38.377059Z",
     "shell.execute_reply": "2024-08-25T01:11:38.376471Z",
     "shell.execute_reply.started": "2024-08-25T01:11:38.371685Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_model(model, device, test_loader, jaccard, dice):\n",
    "    # Initalize average jaccard and dice\n",
    "    average_jaccard = 0\n",
    "    average_dice = 0\n",
    "    # Test the model\n",
    "    model.eval()\n",
    "    for batch_idx, (X,y) in enumerate(test_loader):\n",
    "        # Get batch\n",
    "        image, mask = X.to(device), y.to(device)\n",
    "        # Get results\n",
    "        output = model(image)\n",
    "        average_jaccard += jaccard(torch.where(output > 0.5, 1, 0),torch.where(mask > 0.50, 1, 0)).item()\n",
    "        average_dice += dice(torch.where(output > 0.5, 1, 0),torch.where(mask > 0.50, 1, 0)).item()\n",
    "    # Get average of dice and jaccard scores\n",
    "    average_jaccard /= len(test_loader)\n",
    "    average_dice /= len(test_loader)\n",
    "\n",
    "    # Return values\n",
    "    return average_jaccard, average_dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "Importing the dataset into the Juypter Notebook enviroment for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T01:11:38.378090Z",
     "iopub.status.busy": "2024-08-25T01:11:38.377875Z",
     "iopub.status.idle": "2024-08-25T01:11:38.413309Z",
     "shell.execute_reply": "2024-08-25T01:11:38.412698Z",
     "shell.execute_reply.started": "2024-08-25T01:11:38.378071Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 469739.50it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 459347.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# Path to images and mask\n",
    "image_path = './Kvasir-SEG'\n",
    "# U-Net we are using takes 3 x 256 x 256 images\n",
    "size = 256\n",
    "# Importing the dataset\n",
    "dataset = PolypsSegmentationDataset(image_path,size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "Load the baseline data and indices splits from previous stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T01:11:38.415123Z",
     "iopub.status.busy": "2024-08-25T01:11:38.414906Z",
     "iopub.status.idle": "2024-08-25T01:11:38.428697Z",
     "shell.execute_reply": "2024-08-25T01:11:38.428078Z",
     "shell.execute_reply.started": "2024-08-25T01:11:38.415103Z"
    }
   },
   "outputs": [],
   "source": [
    "# File name\n",
    "name = 'baseline.pt'\n",
    "baseline = torch.load(f=name)\n",
    "# Extract indices and baseline jaccard and dice scores\n",
    "all_indices = baseline['fold_dict']\n",
    "baseline_jaccard = baseline['baseline_jaccard']\n",
    "baseline_dice = baseline['baseline_dice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new dataset\n",
    "Using the model trained on a partition we will create masks the remaining data from the train partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T01:11:38.430044Z",
     "iopub.status.busy": "2024-08-25T01:11:38.429596Z",
     "iopub.status.idle": "2024-08-25T04:51:17.297617Z",
     "shell.execute_reply": "2024-08-25T04:51:17.296719Z",
     "shell.execute_reply.started": "2024-08-25T01:11:38.430021Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/mateuszbuda/brain-segmentation-pytorch/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Split:A|Partition:0.1|NewJaccard:0.39170716817562395|OGJaccard:0.4128429270707644|NewDice:0.5613032854520358|OGDice:0.5833138685960036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Split:A|Partition:0.2|NewJaccard:0.6285151243209839|OGJaccard:0.5926856261033279|NewDice:0.771391355074369|OGDice:0.7437014212975135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "Split:A|Partition:0.3|NewJaccard:0.8299435285421518|OGJaccard:0.7994426122078528|NewDice:0.9066242071298453|OGDice:0.8882140379685622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "Split:A|Partition:0.4|NewJaccard:0.7470610325153058|OGJaccard:0.7497369601176336|NewDice:0.8548097610473633|OGDice:0.856596433199369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Split:A|Partition:0.5|NewJaccard:0.7643875067050641|OGJaccard:0.7510290100024297|NewDice:0.8659477233886719|OGDice:0.8563254429743841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "Split:A|Partition:0.6|NewJaccard:0.8499352152530963|OGJaccard:0.7941618194946876|NewDice:0.9181917630709134|OGDice:0.8843486492450421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "Split:A|Partition:0.7|NewJaccard:0.8671280787541316|OGJaccard:0.847824766085698|NewDice:0.9280819526085486|OGDice:0.917153945335975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Split:B|Partition:0.1|NewJaccard:0.7450273724702688|OGJaccard:0.7485251426696777|NewDice:0.8533747746394231|OGDice:0.8551177978515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "Split:B|Partition:0.2|NewJaccard:0.704290876021752|OGJaccard:0.6979364431821383|NewDice:0.8257925327007587|OGDice:0.8215793462900015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Split:B|Partition:0.3|NewJaccard:0.7375058256662809|OGJaccard:0.838028073310852|NewDice:0.8481808442335862|OGDice:0.9111771216759315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "Split:B|Partition:0.4|NewJaccard:0.812002026117765|OGJaccard:0.7956162828665513|NewDice:0.8959955068734976|OGDice:0.8855276107788086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "Split:B|Partition:0.5|NewJaccard:0.8700093489426833|OGJaccard:0.8628376859884995|NewDice:0.929873173053448|OGDice:0.9262282298161433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "Split:B|Partition:0.6|NewJaccard:0.8662483141972468|OGJaccard:0.871940002991603|NewDice:0.9281478294959435|OGDice:0.9312562942504883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "Split:B|Partition:0.7|NewJaccard:0.8667619961958665|OGJaccard:0.8758463034263024|NewDice:0.928262343773475|OGDice:0.93340881054218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Split:C|Partition:0.1|NewJaccard:0.7533682859860934|OGJaccard:0.7495599801723773|NewDice:0.8590740790733924|OGDice:0.85546691601093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Split:C|Partition:0.2|NewJaccard:0.6649559507003198|OGJaccard:0.6038658894025363|NewDice:0.7982380940363958|OGDice:0.7526745429405799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Split:C|Partition:0.3|NewJaccard:0.7424594989189734|OGJaccard:0.7515174104617193|NewDice:0.8517118600698618|OGDice:0.8572593102088342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Split:C|Partition:0.4|NewJaccard:0.7553714926426227|OGJaccard:0.7502255531457754|NewDice:0.8599540270291842|OGDice:0.8569052769587591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "Split:C|Partition:0.5|NewJaccard:0.850666344165802|OGJaccard:0.8342632146982046|NewDice:0.9186545151930589|OGDice:0.9090637793907752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "Split:C|Partition:0.6|NewJaccard:0.8669178898517902|OGJaccard:0.8603032460579505|NewDice:0.9283576378455529|OGDice:0.9243657038762019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Split:C|Partition:0.7|NewJaccard:0.7815962754763089|OGJaccard:0.7644382302577679|NewDice:0.8765872075007513|OGDice:0.8662427021906927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Split:D|Partition:0.1|NewJaccard:0.707126796245575|OGJaccard:0.7122642489580008|NewDice:0.8276403133685772|OGDice:0.8311265065119817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "Split:D|Partition:0.2|NewJaccard:0.7431545257568359|OGJaccard:0.6683979080273554|NewDice:0.8521884771493765|OGDice:0.8006136233990009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Split:D|Partition:0.3|NewJaccard:0.7394732787058904|OGJaccard:0.7539177582814143|NewDice:0.8498147084162786|OGDice:0.8590316772460938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Split:D|Partition:0.4|NewJaccard:0.7098670693544241|OGJaccard:0.7233358392348657|NewDice:0.8294716614943284|OGDice:0.8388657936683068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "Split:D|Partition:0.5|NewJaccard:0.7538851316158588|OGJaccard:0.7225719048426702|NewDice:0.8588274442232572|OGDice:0.83844360938439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "Split:D|Partition:0.6|NewJaccard:0.7668353181618911|OGJaccard:0.7393910976556631|NewDice:0.8678080485417292|OGDice:0.8499745589036208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Split:D|Partition:0.7|NewJaccard:0.73325993006046|OGJaccard:0.7405328429662265|NewDice:0.8450762675358698|OGDice:0.8505243888268104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "Split:E|Partition:0.1|NewJaccard:0.7811491351861221|OGJaccard:0.7720469878270075|NewDice:0.8766806675837591|OGDice:0.8708260609553411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Split:E|Partition:0.2|NewJaccard:0.7557188180776743|OGJaccard:0.6606472914035504|NewDice:0.8603951380803034|OGDice:0.7952230893648587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "Split:E|Partition:0.3|NewJaccard:0.7845830688109765|OGJaccard:0.7678954509588388|NewDice:0.8784847259521484|OGDice:0.868304546062763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Split:E|Partition:0.4|NewJaccard:0.7375028958687415|OGJaccard:0.7582725332333491|NewDice:0.8486322256234976|OGDice:0.8620426471416767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Split:E|Partition:0.5|NewJaccard:0.6676402871425335|OGJaccard:0.6665022785847003|NewDice:0.7996985362126277|OGDice:0.7993022478543795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Split:E|Partition:0.6|NewJaccard:0.7381908664336572|OGJaccard:0.7438110800889822|NewDice:0.8485045799842248|OGDice:0.8521871566772461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "Split:E|Partition:0.7|NewJaccard:0.8471157550811768|OGJaccard:0.7454458245864282|NewDice:0.9169705464289739|OGDice:0.8534947175246018\n"
     ]
    }
   ],
   "source": [
    "splits = ['A', 'B', 'C', 'D', 'E']\n",
    "partitions = [0.1,0.2,0.3,0.4,0.5,0.6,0.7]\n",
    "\n",
    "# Cycle through all models\n",
    "for split in splits:\n",
    "    for partition in partitions:\n",
    "        # Load the stored data\n",
    "        name = f'./model/Split:{split}|Partition:{partition}'\n",
    "        data = torch.load(name)\n",
    "        # Extract data\n",
    "        train_indices = data['train_indices']\n",
    "        remaining_indices = data['remaining_indices']\n",
    "        test_indices = data['test_indices']\n",
    "        orig_jaccard_score = data['jaccard_score']\n",
    "        orig_dice_score = data['dice_score']\n",
    "        state_dict = data['state_dict']\n",
    "        # Load base model\n",
    "        trained_model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
    "            in_channels=3, out_channels=1, init_features=64, pretrained=False, trust_repo=True).to(device)\n",
    "        # Load saved model\n",
    "        trained_model.load_state_dict(state_dict)\n",
    "        \n",
    "        # Create new dataset\n",
    "        new_dataset = []\n",
    "        # Get train loader for fold\n",
    "        remaining_loader = DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=1,\n",
    "            sampler=torch.utils.data.SubsetRandomSampler(remaining_indices),\n",
    "            num_workers = num_workers\n",
    "        )\n",
    "        # Create masks of remaining data\n",
    "        images, new_masks = create_masks(trained_model, device, remaining_loader)\n",
    "        # Create dataset with new masks\n",
    "        new_dataset.append(BaseDataset(images, new_masks))\n",
    "        # Get images and masks used to train saved model\n",
    "        base_images, base_masks = get_masks(train_indices,dataset)\n",
    "        # Create dataset with ground truth masks and images\n",
    "        new_dataset.append(BaseDataset(base_images, base_masks))\n",
    "        # Concatenate the two so we have a dataset with generated masks and truth maks\n",
    "        # this will be our train dataset\n",
    "        train_dataset = torch.utils.data.ConcatDataset(new_dataset)\n",
    "        \n",
    "        # Create train loader for new dataset\n",
    "        train_loader = DataLoader(\n",
    "            dataset=train_dataset,\n",
    "            batch_size = BATCH_SIZE,\n",
    "            shuffle = True,\n",
    "            num_workers = num_workers,\n",
    "        )    \n",
    "        \n",
    "        ## Initialize the model ##\n",
    "        \n",
    "        # Loading an untrained model to GPU/CPU\n",
    "        model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
    "            in_channels=3, out_channels=1, init_features=64, pretrained=False, trust_repo=True).to(device)\n",
    "        # We will begin our learning rate at 0.01 \n",
    "        lr = 0.01\n",
    "        # Optimizer for model\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,100)\n",
    "        \n",
    "        ## Initialize the training ##\n",
    "    \n",
    "        # Initialize previous and current loss for stopping rule\n",
    "        \n",
    "        L_k = 1 # Previous loss\n",
    "        L_k1 = 0.8 # Current loss\n",
    "        \n",
    "        # To determine in threshold is too low\n",
    "        counter = 0\n",
    "        # Train model until stopping rule is reached\n",
    "        while(stopping_rule(L_k, L_k1, threshold)):\n",
    "            # Assign previous loss for next iteration\n",
    "            L_k = L_k1\n",
    "            # Train model and compute loss\n",
    "            L_k1 = train_model(model, loss_fn, device, train_loader, optimizer)\n",
    "            counter += 1\n",
    "            \n",
    "        # To determine in threshold is too low\n",
    "        print(counter) \n",
    "        \n",
    "        # Get test dataset\n",
    "        test_loader = DataLoader(\n",
    "                dataset=dataset,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                sampler=torch.utils.data.SubsetRandomSampler(test_indices),\n",
    "                num_workers = num_workers,\n",
    "        )\n",
    "        \n",
    "        # Test model on test split\n",
    "        jaccard_score, dice_score = test_model(model, device, test_loader, jaccard, dice)\n",
    "        print(f'Split:{split}|Partition:{partition}|NewJaccard:{jaccard_score}|OGJaccard:{orig_jaccard_score}|NewDice:{dice_score}|OGDice:{orig_dice_score}')\n",
    "        name = f'./new_models/Split:{split}|Partition:{partition}'\n",
    "        # Save model and results\n",
    "        state = {\n",
    "            'state_dict' : model.state_dict(),\n",
    "            'jaccard_score' : jaccard_score,\n",
    "            'dice_score' : dice_score,\n",
    "            'orig_jaccard_score' : orig_jaccard_score,\n",
    "            'orig_dice_score' : orig_dice_score,\n",
    "        }\n",
    "        torch.save(state,f=name)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
